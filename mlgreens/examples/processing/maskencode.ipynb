{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maskencode.ipynb\n",
    "This notebook demonstrates the use of the `mlgreens.data` module to mask & positionally encode 2D Green's function data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from mlgreens import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Green's function data\n",
    "First we'll need some Green's function data to work with. The set in this folder is low in resolution, but sufficient for demonstrating masking and positional encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./GData.h5\"\n",
    "Gdata = data.GreensData(fpath)\n",
    "Lc = Gdata._h5file.attrs[\"Lc\"]\n",
    "a = Gdata._h5file.attrs[\"a\"]\n",
    "n_m, n_lam = Gdata._h5file.attrs[\"n_modes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll randomly choose a sample of the loaded data to use for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "mode = 5\n",
    "m, lam = mode//n_lam, mode%n_lam\n",
    "\n",
    "# Randomly choose a sample from Green's function data\n",
    "rID = np.random.choice(len(Gdata))\n",
    "Gsample = Gdata[rID][..., mode]\n",
    "Glabel = r\"$G_{:s}$\".format(\"{\"+\"{:d}{:d}\".format(m, lam)+\"}\")\n",
    "\n",
    "# Retrieve attribute information for chosen sample\n",
    "sample_attrs = Gdata.get_attrs(rID)\n",
    "sample_group = sample_attrs[\"group\"]\n",
    "sample_xi = sample_attrs[\"xi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create positional encodings & mask patches of data\n",
    "To encode & mask the Green's function data, we'll need to designate sub-patches of the domain space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_dims = np.array([5, 10])\n",
    "patchG = data.patch2D(Gsample, patch_dims)\n",
    "n_patches = len(patchG)\n",
    "G_dims = np.array(patchG.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each patch represents an input to a masked autoencoder, positional encoding is conducted over patches. The single-dimension `PE` values below would be appropriate for a CNN-based autoencoder (CAE), but for an autoencoder without a means of representing spatial information in each input (i.e., without convolutions), we would need to add dimensions for each input patch (`dim = patch_dims.prod()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute positional encodings, scaled to Green's function data\n",
    "dim = 1\n",
    "fenc = .25\n",
    "PE = data.encode(n_patches, dim, n=int(1e2), scale=fenc*patchG.max())\n",
    "\n",
    "# Verify that positional encodings for each patch are unique\n",
    "if len(set(PE.flatten())) != len(PE.flatten()):\n",
    "    print(\"WARNING: Positional encodings not unique!\")\n",
    "else:\n",
    "    print(\"Encoding uniqueness verified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can mask the data & encode it. We'll also create masked version of the encoding for plotting purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute masked versions of Green's data & encoding arrays\n",
    "MG, MiG, _ = data.mask_data(patchG, .6, rseed=1234)\n",
    "MPE, MiPE, _ = data.mask_data(PE, .6, rseed=1234)\n",
    "\n",
    "# Create encoded Green's function arrays\n",
    "EG = np.array([patchG[i] + PE[i] for i in range(n_patches)])\n",
    "MEG = np.array([MG[i] + MPE[i] for i in range(n_patches)])\n",
    "MiEG = np.array([MiG[i] + MiPE[i] for i in range(n_patches)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results\n",
    "Before plotting, we'll rearrange data back into image-like shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize positional encodings for plotting\n",
    "fullPE = np.array([0.*patchG[i] + PE[i] for i in range(n_patches)])\n",
    "fullMPE = np.array([0.*patchG[i] + MPE[i] for i in range(n_patches)])\n",
    "fullMiPE = np.array([0.*patchG[i] + MiPE[i] for i in range(n_patches)])\n",
    "\n",
    "# Unpatch Green's function data\n",
    "plotG = Gsample\n",
    "plotMG = data.unpatch2D(MG, plotG.shape)\n",
    "plotMiG = data.unpatch2D(MiG, plotG.shape)\n",
    "\n",
    "# Unpatch resized positional encodings\n",
    "plotPE = data.unpatch2D(fullPE, plotG.shape)\n",
    "plotMPE = data.unpatch2D(fullMPE, plotG.shape)\n",
    "plotMiPE = data.unpatch2D(fullMiPE, plotG.shape)\n",
    "\n",
    "# Unpatch encoded Green's function data\n",
    "plotEG = data.unpatch2D(EG, plotG.shape)\n",
    "plotMEG = data.unpatch2D(MEG, plotG.shape)\n",
    "plotMiEG = data.unpatch2D(MiEG, plotG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll plot Green's function data, encodings, and their sum. We'll also plot the masked ($M[\\ \\cdot\\ ]$) and hidden ($M^{-1}[\\ \\cdot\\ ]$) version of each value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = [0., Lc*10., 0., sample_xi*a*10]\n",
    "plot_args = {\n",
    "    \"cmap\": 'gray',\n",
    "    \"origin\": 'lower',\n",
    "    \"extent\": ex,\n",
    "    \"aspect\": .6*ex[1]/ex[-1],\n",
    "}\n",
    "plot_data = [[plotG, plotMG, plotMiG], [plotPE, plotMPE, plotMiPE], [plotEG, plotMEG, plotMiEG]]\n",
    "plot_titles = [\n",
    "    [Glabel, r\"$M[$\"+Glabel+r\"$]$\", r\"$M^{-1}[$\"+Glabel+r\"$]$\"],\n",
    "    [r\"$PE$\", r\"$M[PE]$\", r\"$M^{-1}[PE]$\"],\n",
    "    [Glabel+r\"$+PE$\", r\"$M[$\"+Glabel+r\"$+PE]$\", r\"$M^{-1}[$\"+Glabel+r\"$+PE]$\"]\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(3,3, figsize=(15,11))\n",
    "fig.suptitle(r\"Masking & Positional Encoding\", fontsize=24, y=.95)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i,j].set_title(plot_titles[i][j], fontsize=14)\n",
    "        axs[i,j].imshow(plot_data[i][j], **plot_args)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylabel(r\"$R$ (mm)\", fontsize=14)\n",
    "    ax.set_xlabel(r\"$Z$ (mm)\", fontsize=14)\n",
    "    ax.tick_params(labelsize=14)\n",
    "fig.subplots_adjust(hspace=.3, wspace=.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
